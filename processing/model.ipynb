{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "CONNECTION_STRING = \"mongodb://localhost:27017\"\n",
    "client = MongoClient(CONNECTION_STRING)\n",
    "db = client[\"florence\"]\n",
    "collection = db[\"newProducts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "products = collection.find({\"reviews\": {\"$exists\": True, \"$ne\": []}})\n",
    "\n",
    "df = pd.DataFrame(list(products))\n",
    "df=df[[\"id\",\"reviews\",\"starRatings\"]]\n",
    "\n",
    "csv_file = \"reviews.csv\"\n",
    "df.to_csv(csv_file, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "Df = pd.read_csv(\"reviews.csv\")\n",
    "Df['reviews'] = Df['reviews'].apply(literal_eval)\n",
    "Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceApi\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "# model = InferenceApi(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "\n",
    "def get_polarity(text):\n",
    "    result ={}\n",
    "    result[\"positive\"] = 0\n",
    "    result[\"negative\"] = 0\n",
    "    result[\"neutral\"] = 0\n",
    "    output = model(text)\n",
    "    for outcome in output:\n",
    "        if outcome[\"label\"] == \"negative\":\n",
    "            result[\"negative\"] += outcome[\"score\"]\n",
    "        if outcome[\"label\"] == \"positive\":\n",
    "            result[\"positive\"] += outcome[\"score\"]\n",
    "        if outcome[\"label\"] == \"neutral\":\n",
    "            result[\"neutral\"] += outcome[\"score\"]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv  \n",
    "\n",
    "output_csv_file = \"output_results.csv\"\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "file = open(output_csv_file, 'w', newline='', encoding='utf-8')\n",
    "\n",
    "# Create a CSV writer object\n",
    "csv_writer = csv.writer(file)\n",
    "\n",
    "try:\n",
    "    # Write the header row\n",
    "    csv_writer.writerow([\"pid\", \"polarity_positive\",\"polarity_negative\",\"polarity_neutral\", \"star_ratings\"])\n",
    "\n",
    "    # Iterate through the DataFrame\n",
    "    for ind in Df.index:\n",
    "        pid = Df.at[ind, \"id\"]\n",
    "        reviewList = Df.at[ind, \"reviews\"]\n",
    "        \n",
    "        # Average polarity of reviews\n",
    "        result = {}\n",
    "        result[\"positive\"] = 0\n",
    "        result[\"negative\"] = 0\n",
    "        result[\"neutral\"] = 0\n",
    "\n",
    "        try:\n",
    "            for review in reviewList:\n",
    "                output = get_polarity(review[\"review\"])\n",
    "                result[\"positive\"] += output[\"positive\"]\n",
    "                result[\"neutral\"] += output[\"neutral\"]\n",
    "                result[\"negative\"] += output[\"negative\"]\n",
    "\n",
    "            result[\"positive\"] /= len(reviewList)\n",
    "            result[\"negative\"] /= len(reviewList)\n",
    "            result[\"neutral\"] /= len(reviewList)\n",
    "\n",
    "            # Get the starRatings\n",
    "            ratings = Df.at[ind, \"starRatings\"]\n",
    "\n",
    "            # Write the row to the CSV file\n",
    "            csv_writer.writerow([pid, result[\"positive\"],result[\"negative\"],result[\"neutral\"], ratings])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {ind}: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the file in the finally block to ensure it's closed even if an exception occurs\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
